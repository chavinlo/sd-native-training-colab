{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "z_-Ij9278CMp",
        "r591MAby_WHA"
      ],
      "authorship_tag": "ABX9TyOZSggRBwc3M5E82A0krmmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chavinlo/sd-native-training-colab/blob/main/Stable_Diffusion_Native_Training_in_Under_14GB_by_dep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion Native Training in Colab\n",
        "\n",
        "Welcome! In this Colab Notebook we are going to finetune a Stable Diffusion model the native way. No Dreambooth, No Hypernetwork, just Native Training. The same form of training that models like Waifu Diffusion and others are using.\n",
        "\n",
        "Due to the technical limitations of colab, we are only going to be able to train with batch size 1. If you own a GPU with higher vram than 13.5GB, feel free to run this notebook on your computer!\n",
        "\n",
        "If you need more information of need help, feel free to join the SDTL discord server: https://discord.gg/8Sh2T6gjd2\n",
        "\n",
        "### Distributed training\n",
        "You might want to train a bigger model (like, hundreds of thousands of images)\n",
        "\n",
        "This saturday (26th Nov.) we are going to conduct or first distributed training run! If you want to collaborate, join the server (https://discord.gg/8Sh2T6gjd2). Help us by contributing your GPU compute power into a interconected hivemind!\n",
        "\n",
        "### Credits:\n",
        "* [Haru](https://github.com/harubaru/waifu-diffusion) - Diffusers trainer code\n",
        "* Hasuwoof - Bucketing code\n",
        "* Dep (me) - Colab Port\n"
      ],
      "metadata": {
        "id": "WeI6a8-cid4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r1uMLkQS0PFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT!: Change Python version\n",
        "You MUST run this BEFORE ANYTHING ELSE!\n",
        "\n",
        "This will change the python version to 3.9, since certain dependencies (such as scipy) do not have binaries for 3.7 (colab default python version)\n",
        "\n",
        "Run the cell (ONLY THE FIRST ONE) below"
      ],
      "metadata": {
        "id": "tTAqLgZYTlen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#install python 3.9 and dev utils\n",
        "#you may not need all the dev libraries, but I haven't tested which aren't necessary.\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3.9-dev python3.9-distutils libpython3.9-dev\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "\n",
        "# install pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "\n",
        "#install colab's dependencies\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.7/dist-packages/google \\\n",
        "       /usr/local/lib/python3.9/dist-packages/google\n",
        "\n",
        "print(\"RESTARTING KERNEL\")\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "35HQBFL3S820"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the cell above has finished executing, execute the cell below"
      ],
      "metadata": {
        "id": "aVmssPulT9-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check python version\n",
        "import sys\n",
        "print(sys.version)\n",
        "if sys.version_info[1] == 9:\n",
        "  print(\"Success! The running kernel is 3.9+, please continue...\")\n",
        "else:\n",
        "  print(\"Running kernel is not 3.9+... report this\")"
      ],
      "metadata": {
        "id": "iofuI5xRTg5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 0: Dependencies\n",
        "This module will install the required dependencies"
      ],
      "metadata": {
        "id": "-DTplZRvkW4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "A5t3AsrhEwRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers>=0.5.1 numpy==1.23.4 wandb==0.13.4 torch OmegaConf torchvision transformers>=4.21.0 huggingface-hub>=0.10.0 Pillow tqdm==4.64.1 ftfy==6.1.1 bitsandbytes pynvml~=11.4.1 psutil~=5.9.0 accelerate==0.13.1 scipy==1.9.3\n",
        "# !pip install triton==2.0.0.dev20221120\n",
        "# !pip install -q condacolab\n",
        "# import condacolab\n",
        "# condacolab.install()\n",
        "# !conda --version\n",
        "# !conda install xformers -c xformers/label/dev\n",
        "import os"
      ],
      "metadata": {
        "id": "sya5fckXkbQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "K8qR0eLI0NMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 1: Dataset Setup\n",
        "The dataset is the group of Images (and Text) Files we are going to train the model on. The dataset must have the Images and Text files in the same folder, and pairs must match filenames. \n",
        "\n",
        "A more indepth explanation on dataset gathering and organization is available here, along with instructions on building your own: https://docs.google.com/document/d/15j1irOb73WqXG2nxMKpyfnBbJs4yZxbe_rzCSBoi0wQ/edit\n",
        "\n",
        "After you are done building your dataset, you must zip it and follow one of the two options:"
      ],
      "metadata": {
        "id": "FaWBP0-9iue-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Google Drive\n",
        "The fastest option is to download the dataset is using Google Drive.\n",
        "\n",
        "Upload your ZIP file anywhere on your Google Drive that's visible (preferably in the home folder)\n",
        "\n",
        "Then, mount your Google Drive in the \"Files\" Tab:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NpT8mpuliTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@markdown Type the filename of the zipfile in the box below, then execute this cell:\n",
        "filename = \"mio_only.zip\" #@param {type:\"string\"}\n",
        "type_of_folder = \"My Drive\" #@param [\"My Drive\", \"Shared Drive\"]\n",
        "\n",
        "if type_of_folder == \"My Drive\":\n",
        "  os.environ[\"gd_foldertype\"] = \"MyDrive\"\n",
        "elif type_of_folder == \"Shared Drive\":\n",
        "  os.environ[\"gd_foldertype\"] = \"Shareddrives\"\n",
        "\n",
        "os.environ[\"gd_filename\"] = filename\n",
        "\n",
        "!find /content/drive/$gd_foldertype -type f -name $gd_filename > obtained_path.tmp\n",
        "path = str(open(\"obtained_path.tmp\", \"r\").read()).replace('\\n', '').replace('\\r', '')\n",
        "print(\"Path Found: \" + path)\n",
        "print(\"Unzipping\")\n",
        "import zipfile\n",
        "zipobj = zipfile.ZipFile(path, 'r')\n",
        "zipobj.extractall(\"/content/dataset\")\n",
        "zipobj.close()\n",
        "\n",
        "!find /content/dataset -type f -print0 | xargs -0 mv -t /content/dataset\n",
        "!rm -R -- /content/dataset/*/"
      ],
      "metadata": {
        "id": "OJeLfVUzlIUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: Manual Upload\n",
        "This is the simplest but slowest option.\n",
        "\n",
        "Run the cell below, it will give you a box to upload your ZIP file and extract it:"
      ],
      "metadata": {
        "id": "liU4ldbLsvwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3JN6ktwiZBB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print(\"Uploading...\")\n",
        "uploadinfo = files.upload()\n",
        "filename = list(uploadinfo.keys())[0]\n",
        "print(\"Upload succeded\")\n",
        "print(\"Filename: \" + str(filename))\n",
        "print(\"Unzipping\")\n",
        "import zipfile\n",
        "zipobj = zipfile.ZipFile(filename, 'r')\n",
        "zipobj.extractall(\"/content/dataset\")\n",
        "zipobj.close()\n",
        "\n",
        "!find /content/dataset -type f -print0 | xargs -0 mv -t /content/dataset\n",
        "!rm -R -- /content/dataset/*/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Util: Clear Dataset Folder\n",
        "!rm -dr /content/dataset"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dJ9QxG2hr6r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "q0Is6bAt0SbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 2: Model Preparation\n",
        "Here we will chosse the model we want to train on top of (as this is finetuning)\n"
      ],
      "metadata": {
        "id": "5BtN9mA2v4Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Diffuser model from HuggingFaces\n",
        "This is the easiest option because the script uses diffusers, hence, it has direct integration with diffusers models uploaded on the site.\n",
        "\n",
        "Public diffuser models can be downloaded out-of-the-box, but private models or models attached to an EULA (such as Stable Diffusion) require a HuggingFace Token."
      ],
      "metadata": {
        "id": "ZyJCuwjSwNkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Type the name of the model you want to use below:\n",
        "model_name = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "#@markdown If you want to use authentication:\n",
        "\n",
        "#@markdown Tick the box below:\n",
        "enable_authentication = True #@param {type:\"boolean\"}\n",
        "#@markdown Fill this with your HF token (find it at https://huggingface.co/settings/tokens):\n",
        "hf_token_string = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if enable_authentication:\n",
        "  from huggingface_hub import login\n",
        "  login(hf_token_string, False)\n",
        "\n",
        "model_type = \"usual_diffuser\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "TxVye8pjwK58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: CKPT model to Diffusers\n",
        "If you want to train a model on a model thats on CKPT format, you are gonna have to convert it. You can do this with a script, but first you need to upload it."
      ],
      "metadata": {
        "id": "eVEHMQLSyWyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@markdown Due to how big the file is, I'm only going to support Google Drive import. Just like before, upload the CKPT model to your google drive, preferably in the Home folder.\n",
        "\n",
        "#@markdown Type the filename of the CKPT in the box below:\n",
        "filename = \"Filename Goes Here\" #@param {type:\"string\"}\n",
        "type_of_folder = \"My Drive\" #@param [\"My Drive\", \"Shared Drive\"]\n",
        "\n",
        "if type_of_folder == \"My Drive\":\n",
        "  os.environ[\"gd_foldertype\"] = \"MyDrive\"\n",
        "elif type_of_folder == \"Shared Drive\":\n",
        "  os.environ[\"gd_foldertype\"] = \"Shareddrives\"\n",
        "\n",
        "os.environ[\"gd_filename\"] = filename\n",
        "\n",
        "!find /content/drive/$gd_foldertype -type f -name $gd_filename > obtained_path.tmp\n",
        "path = str(open(\"obtained_path.tmp\", \"r\").read()).replace('\\n', '').replace('\\r', '')\n",
        "print(\"Path Found: \" + path)\n",
        "os.environ[\"ckpt_path\"] = path\n",
        "\n",
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/d9cfe325a53502641f16ce4f839391c5b0d0a684/scripts/convert_original_stable_diffusion_to_diffusers.py -O convert.py\n",
        "\n",
        "!py --checkpoint_path $ckpt_path --dump_path /content/diffuser_dump\n",
        "\n",
        "model_name = \"/content/diffuser_dump\"\n",
        "model_type = \"converted_from_ckpt\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "goL4G9Hoyw2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EqB1PpMJ0TiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 3: Training\n",
        "\n",
        "This is the most important section and the one that will take the most time.\n",
        "\n",
        "Please make sure you have: Downloaded the dataset and Set up the model to train on top of."
      ],
      "metadata": {
        "id": "GDR0njubz4EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Configuration\n",
        "#@markdown Select the configuration to use during training. A brief description is provided.\n",
        "\n",
        "#@markdown ### Required\n",
        "#@markdown Name of the finetune run\n",
        "run_name = \"myNewFinetune\" #@param {type:\"string\"}\n",
        "model = model_name\n",
        "dataset_path = \"/content/dataset/\"\n",
        "print(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KtpZ7yC06R4",
        "outputId": "51d83950-f064-4d5f-a147-e85a521f435f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional\n",
        "You MUST run this cell too. If you want you can open it and modify it, but remember, the default settings are the recommended ones. You might break the configuration if you change something you don't know."
      ],
      "metadata": {
        "id": "z_-Ij9278CMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown Learning Rate (converted to float)\n",
        "input_lr = \"5e-6\" #@param {type:\"string\"}\n",
        "lr = float(input_lr)\n",
        "#@markdown Number of epochs to train for\n",
        "epochs = 10 #@param {type:\"integer\"}\n",
        "#@markdown Batch size (More consumes more VRAM)\n",
        "batch_size = 1 #@param {type:\"integer\"}\n",
        "#@markdown Enable Gradient Checkpointing (Less VRAM usage)\n",
        "gradient_checkpointing = True #@param {type:\"boolean\"}\n",
        "#@markdown Use 8-bit Adam Optimizer (only works in certain setups)\n",
        "use_8bit_adam = True #@param {type:\"boolean\"}\n",
        "#@markdown Seed for random number generator, this is to be used for reproduceability purposes.\n",
        "seed = 42 #@param {type:\"integer\"}\n",
        "#@markdown Root path for all outputs\n",
        "output_path = \"/content/output\" #@param {type:\"string\"}\n",
        "#@markdown Number of steps to save checkpoints at. Set this to a high number to avoid filling up space.\n",
        " \n",
        "#@markdown batch size * number of images = total number of steps\n",
        "save_steps = 1000 #@param {type:\"integer\"}\n",
        "#@markdown Train in mixed precision\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown Use penultimate CLIP layer for text embedding\n",
        "clip_penultimate = True #@param {type:\"boolean\"}\n",
        "#@markdown Resize dataset Images (Highly recommended)\n",
        "resize = True #@param {type:\"boolean\"}\n",
        "#@markdown Use memory efficient attention (Do not enable, broken at the moment)\n",
        "use_xformers = False #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j_a88ngQ7NTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### WeightsAndBiases Reporting\n",
        "#@markdown Enable Weights and Biases Reporting\n",
        "enablewandb = False #@param {type:\"boolean\"}\n",
        "#@markdown Project ID for reporting to WandB\n",
        "project_id = \"\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O_y80qsw7RRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Inference Configuration\n",
        "#@markdown Enable Inference during training (Consumes 2GB of VRAM)\n",
        "enableinference = False #@param {type:\"boolean\"}\n",
        "#@markdown Number of steps to log images at.\n",
        "image_log_steps = 500 #@param {type:\"integer\"}\n",
        "#@markdown Number of images to log every image_log_steps\n",
        "image_log_amount = 5 #@param {type:\"integer\"}\n",
        "#@markdown Number of inference steps to use to log images.\n",
        "image_log_inference_steps = 25 #@param {type:\"integer\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xm9OTSHP7W8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Advanced\n",
        "#@markdown Perform extended validation of images to catch truncated or corrupt images.\n",
        "extended_validation = False #@param {type:\"boolean\"}\n",
        "#@markdown Skip validation of images, useful for speeding up loading of very large datasets that have already been validated.\n",
        "skip_validation = False #@param {type:\"boolean\"}\n",
        "#@markdown Number of buckets\n",
        "num_buckets = 16 #@param {type:\"integer\"}\n",
        "#@markdown The minimum side length of a bucket.\n",
        "bucket_side_min = 256 #@param {type:\"integer\"}\n",
        "#@markdown The maximum side length of a bucket.\n",
        "bucket_side_max = 256 #@param {type:\"integer\"}\n",
        "#@markdown Use EMA for finetuning\n",
        "use_ema = False #@param {type:\"boolean\"}\n",
        "#@markdown Percentage chance of dropping out the text condition per batch. Ranges from 0.0 to 1.0 where 1.0 means 100% text condition dropout.\n",
        "ucg_input = \"0.1\" #@param {type:\"string\"}\n",
        "ucg = float(ucg_input)\n",
        "\n",
        "no_migration = True"
      ],
      "metadata": {
        "id": "8HXPod2B7Qu3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "r591MAby_WHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import argparse\n",
        "import socket\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import diffusers\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import tqdm\n",
        "import resource\n",
        "import psutil\n",
        "import pynvml\n",
        "import wandb\n",
        "import gc\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import traceback\n",
        "import shutil\n",
        "\n",
        "from typing import Iterable\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler, PNDMScheduler, DDIMScheduler, StableDiffusionPipeline\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "from diffusers.optimization import get_scheduler\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "from PIL import Image, ImageOps\n",
        "from PIL.Image import Image as Img\n",
        "\n",
        "from typing import Dict, List, Generator, Tuple\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "i0gB3eL587j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bucketing things\n",
        "\n",
        "def _sort_by_ratio(bucket: tuple) -> float:\n",
        "    return bucket[0] / bucket[1]\n",
        "\n",
        "def _sort_by_area(bucket: tuple) -> float:\n",
        "    return bucket[0] * bucket[1]\n",
        "\n",
        "class Validation():\n",
        "    def __init__(self, is_skipped: bool, is_extended: bool) -> None:\n",
        "        if is_skipped:\n",
        "            self.validate = self.__no_op\n",
        "            return print(\"Validation: Skipped\")\n",
        "\n",
        "        if is_extended:\n",
        "            self.validate = self.__extended_validate\n",
        "            return print(\"Validation: Extended\")\n",
        "\n",
        "        self.validate = self.__validate\n",
        "        print(\"Validation: Standard\")\n",
        "\n",
        "    def __validate(self, fp: str) -> bool:\n",
        "        try:\n",
        "            Image.open(fp)\n",
        "            return True\n",
        "        except:\n",
        "            print(f'WARNING: Image cannot be opened: {fp}')\n",
        "            return False\n",
        "\n",
        "    def __extended_validate(self, fp: str) -> bool:\n",
        "        try:\n",
        "            Image.open(fp).load()\n",
        "            return True\n",
        "        except (OSError) as error:\n",
        "            if 'truncated' in str(error):\n",
        "                print(f'WARNING: Image truncated: {error}')\n",
        "                return False\n",
        "            print(f'WARNING: Image cannot be opened: {error}')\n",
        "            return False\n",
        "        except:\n",
        "            print(f'WARNING: Image cannot be opened: {error}')\n",
        "            return False\n",
        "\n",
        "    def __no_op(self, fp: str) -> bool:\n",
        "        return True\n",
        "\n",
        "class Resize():\n",
        "    def __init__(self, is_resizing: bool, is_not_migrating: bool) -> None:\n",
        "        if not is_resizing:\n",
        "            self.resize = self.__no_op\n",
        "            return\n",
        "\n",
        "        if not is_not_migrating:\n",
        "            self.resize = self.__migration\n",
        "            dataset_path = os.path.split(dataset_path)\n",
        "            self.__directory = os.path.join(\n",
        "                dataset_path[0],\n",
        "                f'{dataset_path[1]}_cropped'\n",
        "            )\n",
        "            os.makedirs(self.__directory, exist_ok=True)\n",
        "            return print(f\"Resizing: Performing migration to '{self.__directory}'.\")\n",
        "\n",
        "        self.resize = self.__no_migration\n",
        "\n",
        "    def __no_migration(self, image_path: str, w: int, h: int) -> Img:\n",
        "        return ImageOps.fit(\n",
        "                Image.open(image_path),\n",
        "                (w, h),\n",
        "                bleed=0.0,\n",
        "                centering=(0.5, 0.5),\n",
        "                method=Image.Resampling.LANCZOS\n",
        "            ).convert(mode='RGB')\n",
        "\n",
        "    def __migration(self, image_path: str, w: int, h: int) -> Img:\n",
        "        filename = re.sub('\\.[^/.]+$', '', os.path.split(image_path)[1])\n",
        "\n",
        "        image = ImageOps.fit(\n",
        "                Image.open(image_path),\n",
        "                (w, h),\n",
        "                bleed=0.0,\n",
        "                centering=(0.5, 0.5),\n",
        "                method=Image.Resampling.LANCZOS\n",
        "            ).convert(mode='RGB')\n",
        "\n",
        "        image.save(\n",
        "            os.path.join(f'{self.__directory}', f'{filename}.jpg'),\n",
        "            optimize=True\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            shutil.copy(\n",
        "                os.path.join(dataset_path, f'{filename}.txt'),\n",
        "                os.path.join(self.__directory, f'{filename}.txt'),\n",
        "                follow_symlinks=False\n",
        "            )\n",
        "        except (FileNotFoundError):\n",
        "            f = open(\n",
        "                os.path.join(self.__directory, f'{filename}.txt'),\n",
        "                'w',\n",
        "                encoding='UTF-8'\n",
        "            )\n",
        "            f.close()\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __no_op(self, image_path: str, w: int, h: int) -> Img:\n",
        "        return Image.open(image_path)\n",
        "\n",
        "class ImageStore:\n",
        "    def __init__(self, data_dir: str) -> None:\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.image_files = []\n",
        "        [self.image_files.extend(glob.glob(f'{data_dir}' + '/*.' + e)) for e in ['jpg', 'jpeg', 'png', 'bmp', 'webp']]\n",
        "\n",
        "        self.validator = Validation(\n",
        "            skip_validation,\n",
        "            extended_validation\n",
        "        ).validate\n",
        "\n",
        "        self.resizer = Resize(resize, no_migration).resize\n",
        "\n",
        "        self.image_files = [x for x in self.image_files if self.validator(x)]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_files)\n",
        "\n",
        "    # iterator returns images as PIL images and their index in the store\n",
        "    def entries_iterator(self) -> Generator[Tuple[Img, int], None, None]:\n",
        "        for f in range(len(self)):\n",
        "            yield Image.open(self.image_files[f]), f\n",
        "\n",
        "    # get image by index\n",
        "    def get_image(self, ref: Tuple[int, int, int]) -> Img:\n",
        "        return self.resizer(\n",
        "            self.image_files[ref[0]],\n",
        "            ref[1],\n",
        "            ref[2]\n",
        "        )\n",
        "\n",
        "    # gets caption by removing the extension from the filename and replacing it with .txt\n",
        "    def get_caption(self, ref: Tuple[int, int, int]) -> str:\n",
        "        filename = re.sub('\\.[^/.]+$', '', self.image_files[ref[0]]) + '.txt'\n",
        "        with open(filename, 'r', encoding='UTF-8') as f:\n",
        "            return f.read()\n",
        "\n",
        "\n",
        "# ====================================== #\n",
        "# Bucketing code stolen from hasuwoof:   #\n",
        "# https://github.com/hasuwoof/huskystack #\n",
        "# ====================================== #\n",
        "\n",
        "class AspectBucket:\n",
        "    def __init__(self, store: ImageStore,\n",
        "                 num_buckets: int,\n",
        "                 batch_size: int,\n",
        "                 bucket_side_min: int = 256,\n",
        "                 bucket_side_max: int = 768,\n",
        "                 bucket_side_increment: int = 64,\n",
        "                 max_image_area: int = 512 * 768,\n",
        "                 max_ratio: float = 2):\n",
        "\n",
        "        self.requested_bucket_count = num_buckets\n",
        "        self.bucket_length_min = bucket_side_min\n",
        "        self.bucket_length_max = bucket_side_max\n",
        "        self.bucket_increment = bucket_side_increment\n",
        "        self.max_image_area = max_image_area\n",
        "        self.batch_size = batch_size\n",
        "        self.total_dropped = 0\n",
        "\n",
        "        if max_ratio <= 0:\n",
        "            self.max_ratio = float('inf')\n",
        "        else:\n",
        "            self.max_ratio = max_ratio\n",
        "\n",
        "        self.store = store\n",
        "        self.buckets = []\n",
        "        self._bucket_ratios = []\n",
        "        self._bucket_interp = None\n",
        "        self.bucket_data: Dict[tuple, List[int]] = dict()\n",
        "        self.init_buckets()\n",
        "        self.fill_buckets()\n",
        "\n",
        "    def init_buckets(self):\n",
        "        possible_lengths = list(range(self.bucket_length_min, self.bucket_length_max + 1, self.bucket_increment))\n",
        "        possible_buckets = list((w, h) for w, h in itertools.product(possible_lengths, possible_lengths)\n",
        "                        if w >= h and w * h <= self.max_image_area and w / h <= self.max_ratio)\n",
        "\n",
        "        buckets_by_ratio = {}\n",
        "\n",
        "        # group the buckets by their aspect ratios\n",
        "        for bucket in possible_buckets:\n",
        "            w, h = bucket\n",
        "            # use precision to avoid spooky floats messing up your day\n",
        "            ratio = '{:.4e}'.format(w / h)\n",
        "\n",
        "            if ratio not in buckets_by_ratio:\n",
        "                group = set()\n",
        "                buckets_by_ratio[ratio] = group\n",
        "            else:\n",
        "                group = buckets_by_ratio[ratio]\n",
        "\n",
        "            group.add(bucket)\n",
        "\n",
        "        # now we take the list of buckets we generated and pick the largest by area for each (the first sorted)\n",
        "        # then we put all of those in a list, sorted by the aspect ratio\n",
        "        # the square bucket (LxL) will be the first\n",
        "        unique_ratio_buckets = sorted([sorted(buckets, key=_sort_by_area)[-1]\n",
        "                                       for buckets in buckets_by_ratio.values()], key=_sort_by_ratio)\n",
        "\n",
        "        # how many buckets to create for each side of the distribution\n",
        "        bucket_count_each = int(np.clip((self.requested_bucket_count + 1) / 2, 1, len(unique_ratio_buckets)))\n",
        "\n",
        "        # we know that the requested_bucket_count must be an odd number, so the indices we calculate\n",
        "        # will include the square bucket and some linearly spaced buckets along the distribution\n",
        "        indices = {*np.linspace(0, len(unique_ratio_buckets) - 1, bucket_count_each, dtype=int)}\n",
        "\n",
        "        # make the buckets, make sure they are unique (to remove the duplicated square bucket), and sort them by ratio\n",
        "        # here we add the portrait buckets by reversing the dimensions of the landscape buckets we generated above\n",
        "        buckets = sorted({*(unique_ratio_buckets[i] for i in indices),\n",
        "                          *(tuple(reversed(unique_ratio_buckets[i])) for i in indices)}, key=_sort_by_ratio)\n",
        "\n",
        "        self.buckets = buckets\n",
        "\n",
        "        # cache the bucket ratios and the interpolator that will be used for calculating the best bucket later\n",
        "        # the interpolator makes a 1d piecewise interpolation where the input (x-axis) is the bucket ratio,\n",
        "        # and the output is the bucket index in the self.buckets array\n",
        "        # to find the best fit we can just round that number to get the index\n",
        "        self._bucket_ratios = [w / h for w, h in buckets]\n",
        "        if len(self._bucket_ratios) > 1:\n",
        "          self._bucket_interp = interp1d(self._bucket_ratios, list(range(len(buckets))), assume_sorted=True, fill_value=None)\n",
        "        else:\n",
        "          self._bucket_interp = lambda *_: 0\n",
        "\n",
        "        for b in buckets:\n",
        "            self.bucket_data[b] = []\n",
        "\n",
        "    def get_batch_count(self):\n",
        "        return sum(len(b) // self.batch_size for b in self.bucket_data.values())\n",
        "\n",
        "    def get_bucket_info(self):\n",
        "        return json.dumps({ \"buckets\": self.buckets, \"bucket_ratios\": self._bucket_ratios })\n",
        "\n",
        "    def get_batch_iterator(self) -> Generator[Tuple[Tuple[int, int, int]], None, None]:\n",
        "        \"\"\"\n",
        "        Generator that provides batches where the images in a batch fall on the same bucket\n",
        "\n",
        "        Each element generated will be:\n",
        "            (index, w, h)\n",
        "\n",
        "        where each image is an index into the dataset\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        max_bucket_len = max(len(b) for b in self.bucket_data.values())\n",
        "        index_schedule = list(range(max_bucket_len))\n",
        "        random.shuffle(index_schedule)\n",
        "\n",
        "        bucket_len_table = {\n",
        "            b: len(self.bucket_data[b]) for b in self.buckets\n",
        "        }\n",
        "\n",
        "        bucket_schedule = []\n",
        "        for i, b in enumerate(self.buckets):\n",
        "            bucket_schedule.extend([i] * (bucket_len_table[b] // self.batch_size))\n",
        "\n",
        "        random.shuffle(bucket_schedule)\n",
        "\n",
        "        bucket_pos = {\n",
        "            b: 0 for b in self.buckets\n",
        "        }\n",
        "\n",
        "        total_generated_by_bucket = {\n",
        "            b: 0 for b in self.buckets\n",
        "        }\n",
        "\n",
        "        for bucket_index in bucket_schedule:\n",
        "            b = self.buckets[bucket_index]\n",
        "            i = bucket_pos[b]\n",
        "            bucket_len = bucket_len_table[b]\n",
        "\n",
        "            batch = []\n",
        "            while len(batch) != self.batch_size:\n",
        "                # advance in the schedule until we find an index that is contained in the bucket\n",
        "                k = index_schedule[i]\n",
        "                if k < bucket_len:\n",
        "                    entry = self.bucket_data[b][k]\n",
        "                    batch.append(entry)\n",
        "\n",
        "                i += 1\n",
        "\n",
        "            total_generated_by_bucket[b] += self.batch_size\n",
        "            bucket_pos[b] = i\n",
        "            yield [(idx, *b) for idx in batch]\n",
        "\n",
        "    def fill_buckets(self):\n",
        "        entries = self.store.entries_iterator()\n",
        "        total_dropped = 0\n",
        "\n",
        "        for entry, index in tqdm.tqdm(entries, total=len(self.store)):\n",
        "            if not self._process_entry(entry, index):\n",
        "                total_dropped += 1\n",
        "\n",
        "        for b, values in self.bucket_data.items():\n",
        "            # shuffle the entries for extra randomness and to make sure dropped elements are also random\n",
        "            random.shuffle(values)\n",
        "\n",
        "            # make sure the buckets have an exact number of elements for the batch\n",
        "            to_drop = len(values) % self.batch_size\n",
        "            self.bucket_data[b] = list(values[:len(values) - to_drop])\n",
        "            total_dropped += to_drop\n",
        "\n",
        "        self.total_dropped = total_dropped\n",
        "\n",
        "    def _process_entry(self, entry: Image.Image, index: int) -> bool:\n",
        "        aspect = entry.width / entry.height\n",
        "\n",
        "        if aspect > self.max_ratio or (1 / aspect) > self.max_ratio:\n",
        "            return False\n",
        "\n",
        "        best_bucket = self._bucket_interp(aspect)\n",
        "\n",
        "        if best_bucket is None:\n",
        "            return False\n",
        "\n",
        "        bucket = self.buckets[round(float(best_bucket))]\n",
        "\n",
        "        self.bucket_data[bucket].append(index)\n",
        "\n",
        "        del entry\n",
        "\n",
        "        return True\n",
        "\n",
        "class AspectBucketSampler(torch.utils.data.Sampler):\n",
        "    def __init__(self, bucket: AspectBucket, num_replicas: int = 1, rank: int = 0):\n",
        "        super().__init__(None)\n",
        "        self.bucket = bucket\n",
        "        self.num_replicas = num_replicas\n",
        "        self.rank = rank\n",
        "\n",
        "    def __iter__(self):\n",
        "        # subsample the bucket to only include the elements that are assigned to this rank\n",
        "        indices = self.bucket.get_batch_iterator()\n",
        "        indices = list(indices)[self.rank::self.num_replicas]\n",
        "        return iter(indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.bucket.get_batch_count() // self.num_replicas\n",
        "\n",
        "class AspectDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, store: ImageStore, tokenizer: CLIPTokenizer, ucg: float = 0.1):\n",
        "        self.store = store\n",
        "        self.tokenizer = tokenizer\n",
        "        self.ucg = ucg\n",
        "\n",
        "        self.transforms = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize([0.5], [0.5])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.store)\n",
        "\n",
        "    def __getitem__(self, item: Tuple[int, int, int]):\n",
        "        return_dict = {'pixel_values': None, 'input_ids': None}\n",
        "\n",
        "        image_file = self.store.get_image(item)\n",
        "\n",
        "        return_dict['pixel_values'] = self.transforms(image_file)\n",
        "        if random.random() > self.ucg:\n",
        "            caption_file = self.store.get_caption(item)\n",
        "        else:\n",
        "            caption_file = ''\n",
        "        return_dict['input_ids'] = self.tokenizer(caption_file, max_length=self.tokenizer.model_max_length, padding='do_not_pad', truncation=True).input_ids\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "    def collate_fn(self, examples):\n",
        "            pixel_values = torch.stack([example['pixel_values'] for example in examples if example is not None])\n",
        "            pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "            input_ids = [example['input_ids'] for example in examples if example is not None]\n",
        "            padded_tokens = self.tokenizer.pad({'input_ids': input_ids}, return_tensors='pt', padding=True)\n",
        "            return {\n",
        "                'pixel_values': pixel_values,\n",
        "                'input_ids': padded_tokens.input_ids,\n",
        "                'attention_mask': padded_tokens.attention_mask,\n",
        "            }\n"
      ],
      "metadata": {
        "id": "IrqUobUI8uhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from torch-ema https://github.com/fadel/pytorch_ema/blob/master/torch_ema/ema.py#L14\n",
        "class EMAModel:\n",
        "    \"\"\"\n",
        "    Exponential Moving Average of models weights\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parameters: Iterable[torch.nn.Parameter], decay=0.9999):\n",
        "        parameters = list(parameters)\n",
        "        self.shadow_params = [p.clone().detach() for p in parameters]\n",
        "\n",
        "        self.decay = decay\n",
        "        self.optimization_step = 0\n",
        "\n",
        "    def get_decay(self, optimization_step):\n",
        "        \"\"\"\n",
        "        Compute the decay factor for the exponential moving average.\n",
        "        \"\"\"\n",
        "        value = (1 + optimization_step) / (10 + optimization_step)\n",
        "        return 1 - min(self.decay, value)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, parameters):\n",
        "        parameters = list(parameters)\n",
        "\n",
        "        self.optimization_step += 1\n",
        "        self.decay = self.get_decay(self.optimization_step)\n",
        "\n",
        "        for s_param, param in zip(self.shadow_params, parameters):\n",
        "            if param.requires_grad:\n",
        "                tmp = self.decay * (s_param - param)\n",
        "                s_param.sub_(tmp)\n",
        "            else:\n",
        "                s_param.copy_(param)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def copy_to(self, parameters: Iterable[torch.nn.Parameter]) -> None:\n",
        "        \"\"\"\n",
        "        Copy current averaged parameters into given collection of parameters.\n",
        "        Args:\n",
        "            parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
        "                updated with the stored moving averages. If `None`, the\n",
        "                parameters with which this `ExponentialMovingAverage` was\n",
        "                initialized will be used.\n",
        "        \"\"\"\n",
        "        parameters = list(parameters)\n",
        "        for s_param, param in zip(self.shadow_params, parameters):\n",
        "            param.data.copy_(s_param.data)\n",
        "\n",
        "    # From CompVis LitEMA implementation\n",
        "    def store(self, parameters):\n",
        "        \"\"\"\n",
        "        Save the current parameters for restoring later.\n",
        "        Args:\n",
        "          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
        "            temporarily stored.\n",
        "        \"\"\"\n",
        "        self.collected_params = [param.clone() for param in parameters]\n",
        "\n",
        "    def restore(self, parameters):\n",
        "        \"\"\"\n",
        "        Restore the parameters stored with the `store` method.\n",
        "        Useful to validate the model with EMA parameters without affecting the\n",
        "        original optimization process. Store the parameters before the\n",
        "        `copy_to` method. After validation (or model saving), use this to\n",
        "        restore the former parameters.\n",
        "        Args:\n",
        "          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n",
        "            updated with the stored parameters.\n",
        "        \"\"\"\n",
        "        for c_param, param in zip(self.collected_params, parameters):\n",
        "            param.data.copy_(c_param.data)\n",
        "\n",
        "        del self.collected_params\n",
        "        gc.collect()\n",
        "\n",
        "    def to(self, device=None, dtype=None) -> None:\n",
        "        r\"\"\"Move internal buffers of the ExponentialMovingAverage to `device`.\n",
        "        Args:\n",
        "            device: like `device` argument to `torch.Tensor.to`\n",
        "        \"\"\"\n",
        "        # .to() on the tensors handles None correctly\n",
        "        self.shadow_params = [\n",
        "            p.to(device=device, dtype=dtype) if p.is_floating_point() else p.to(device=device)\n",
        "            for p in self.shadow_params\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "TTjprdFW_QKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run!"
      ],
      "metadata": {
        "id": "kCG6ejCz_jSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "mode = 'disabled'\n",
        "if enablewandb:\n",
        "    mode = 'online'\n",
        "if hf_token_string is not None:\n",
        "    os.environ['HF_API_TOKEN'] = hf_token_string\n",
        "    hf_token_string = None\n",
        "run = wandb.init(project=project_id, name=run_name, dir=output_path+'/wandb', mode=mode)\n",
        "\n",
        "# Inform the user of host, and various versions -- useful for debugging issues.\n",
        "print(\"RUN_NAME:\", run_name)\n",
        "print(\"HOST:\", socket.gethostname())\n",
        "print(\"CUDA:\", torch.version.cuda)\n",
        "print(\"TORCH:\", torch.__version__)\n",
        "print(\"TRANSFORMERS:\", transformers.__version__)\n",
        "print(\"DIFFUSERS:\", diffusers.__version__)\n",
        "print(\"MODEL:\", model_name)\n",
        "print(\"FP16:\", fp16)\n",
        "resolution = 512\n",
        "print(\"RESOLUTION:\", resolution)\n",
        "\n",
        "if hf_token_string is not None:\n",
        "    print('It is recommended to set the HF_API_TOKEN environment variable instead of passing it as a command line argument since WandB will automatically log it.')\n",
        "else:\n",
        "    try:\n",
        "        hf_token_string = os.environ['HF_API_TOKEN']\n",
        "        print(\"HF Token set via enviroment variable\")\n",
        "    except Exception:\n",
        "        print(\"No HF Token detected in arguments or enviroment variable, setting it to none (as in string)\")\n",
        "        hf_token_string = \"none\"\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "print(\"DEVICE:\", device)\n",
        "\n",
        "# setup fp16 stuff\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=fp16)\n",
        "\n",
        "# Set seed\n",
        "torch.manual_seed(seed)\n",
        "print('RANDOM SEED:', seed)\n",
        "\n",
        "#TODO: not yet\n",
        "# if args.resume:\n",
        "#     args.model = args.resume\n",
        "\n",
        "tokenizer = CLIPTokenizer.from_pretrained(model_name, subfolder='tokenizer', use_auth_token=hf_token_string)\n",
        "text_encoder = CLIPTextModel.from_pretrained(model_name, subfolder='text_encoder', use_auth_token=hf_token_string)\n",
        "vae = AutoencoderKL.from_pretrained(model_name, subfolder='vae', use_auth_token=hf_token_string)\n",
        "unet = UNet2DConditionModel.from_pretrained(model_name, subfolder='unet', use_auth_token=hf_token_string)\n",
        "\n",
        "\n",
        "# Freeze vae and text_encoder\n",
        "vae.requires_grad_(False)\n",
        "text_encoder.requires_grad_(False)\n",
        "\n",
        "if gradient_checkpointing:\n",
        "    unet.enable_gradient_checkpointing()\n",
        "\n",
        "if use_xformers:\n",
        "    unet.set_use_memory_efficient_attention_xformers(True)\n",
        "\n",
        "# \"The safer approach would be to move the model to the device first and create the optimizer afterwards.\"\n",
        "weight_dtype = torch.float16 if fp16 else torch.float32\n",
        "\n",
        "# move models to device\n",
        "vae = vae.to(device, dtype=weight_dtype)\n",
        "unet = unet.to(device, dtype=torch.float32)\n",
        "text_encoder = text_encoder.to(device, dtype=weight_dtype)\n",
        "    \n",
        "if use_8bit_adam: # Bits and bytes is only supported on certain CUDA setups, so default to regular adam if it fails.\n",
        "    try:\n",
        "        import bitsandbytes as bnb\n",
        "        optimizer_cls = bnb.optim.AdamW8bit\n",
        "    except:\n",
        "        print('bitsandbytes not supported, using regular Adam optimizer')\n",
        "        optimizer_cls = torch.optim.AdamW\n",
        "else:\n",
        "    optimizer_cls = torch.optim.AdamW\n",
        "\n",
        "optimizer = optimizer_cls(\n",
        "    unet.parameters(),\n",
        "    lr=lr,\n",
        "    betas=(float(0.9), float(0.999)),\n",
        "    eps=float(1e-2),\n",
        "    weight_decay=float(1e-2),\n",
        ")\n",
        "\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    beta_start=0.00085,\n",
        "    beta_end=0.012,\n",
        "    beta_schedule='scaled_linear',\n",
        "    num_train_timesteps=1000,\n",
        "    clip_sample=False\n",
        ")\n",
        "\n",
        "# load dataset\n",
        "print(\"Dataset located at: \", dataset_path)\n",
        "store = ImageStore(dataset_path)\n",
        "print(f'STORE_LEN: {len(store)}')\n",
        "dataset = AspectDataset(store, tokenizer)\n",
        "bucket = AspectBucket(store, num_buckets, batch_size, bucket_side_min, bucket_side_max, 64, resolution * resolution, 2.0)\n",
        "sampler = AspectBucketSampler(bucket=bucket, num_replicas=1, rank=0)\n",
        "\n",
        "\n",
        "\n",
        "# if args.output_bucket_info:\n",
        "#     print(bucket.get_bucket_info())\n",
        "#     exit(0)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_sampler=sampler,\n",
        "    num_workers=0,\n",
        "    collate_fn=dataset.collate_fn\n",
        ")\n",
        "\n",
        "# Migrate dataset\n",
        "if resize and not no_migration:\n",
        "    for _, batch in enumerate(train_dataloader):\n",
        "        continue\n",
        "    print(f\"Completed resize and migration to '{dataset_path}_cropped' please relaunch the trainer without the --resize argument and train on the migrated dataset.\")\n",
        "    exit(0)\n",
        "\n",
        "#unet = torch.nn.parallel.DistributedDataParallel(unet, device_ids=[rank], output_device=rank, gradient_as_bucket_view=True)\n",
        "\n",
        "# create ema\n",
        "if use_ema:\n",
        "    ema_unet = EMAModel(unet.parameters())\n",
        "\n",
        "num_steps_per_epoch = len(train_dataloader)\n",
        "progress_bar = tqdm.tqdm(range(epochs * num_steps_per_epoch), desc=\"Total Steps\", leave=False)\n",
        "global_step = 0\n",
        "\n",
        "# if args.resume:\n",
        "#     target_global_step = int(args.resume.split('_')[-1])\n",
        "#     print(f'resuming from {args.resume}...')\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"cosine\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=int(float(0.05) * num_steps_per_epoch * epochs),\n",
        "    num_training_steps=epochs * num_steps_per_epoch,\n",
        "    #last_epoch=(global_step // num_steps_per_epoch) - 1,\n",
        ")\n",
        "\n",
        "def save_checkpoint(global_step):\n",
        "      if use_ema:\n",
        "          ema_unet.store(unet.parameters())\n",
        "          ema_unet.copy_to(unet.parameters())\n",
        "      pipeline = StableDiffusionPipeline(\n",
        "          text_encoder=text_encoder,\n",
        "          vae=vae,\n",
        "          unet=unet,\n",
        "          tokenizer=tokenizer,\n",
        "          scheduler=PNDMScheduler(\n",
        "              beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True\n",
        "          ),\n",
        "          safety_checker=StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\"),\n",
        "          feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
        "      )\n",
        "      print(f'saving checkpoint to: {output_path}/{run_name}_{global_step}')\n",
        "      pipeline.save_pretrained(f'{output_path}/{run_name}_{global_step}')\n",
        "\n",
        "      if use_ema:\n",
        "          ema_unet.restore(unet.parameters())\n",
        "\n",
        "try:\n",
        "    loss = torch.tensor(0.0, device=device, dtype=weight_dtype)\n",
        "    for epoch in range(epochs):\n",
        "        unet.train()\n",
        "        for _, batch in enumerate(train_dataloader):\n",
        "            # if args.resume and global_step < target_global_step:\n",
        "            #     if rank == 0:\n",
        "            #         progress_bar.update(1)\n",
        "            #     global_step += 1\n",
        "            #     continue\n",
        "            b_start = time.perf_counter()\n",
        "            latents = vae.encode(batch['pixel_values'].to(device, dtype=weight_dtype)).latent_dist.sample()\n",
        "            latents = latents * 0.18215\n",
        "\n",
        "            # Sample noise\n",
        "            noise = torch.randn_like(latents)\n",
        "            bsz = latents.shape[0]\n",
        "            # Sample a random timestep for each image\n",
        "            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bsz,), device=latents.device)\n",
        "            timesteps = timesteps.long()\n",
        "\n",
        "            # Add noise to the latents according to the noise magnitude at each timestep\n",
        "            # (this is the forward diffusion process)\n",
        "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
        "\n",
        "            # Get the text embedding for conditioning\n",
        "            encoder_hidden_states = text_encoder(batch['input_ids'].to(device), output_hidden_states=True)\n",
        "            if clip_penultimate:\n",
        "                encoder_hidden_states = text_encoder.text_model.final_layer_norm(encoder_hidden_states['hidden_states'][-2])\n",
        "            else:\n",
        "                encoder_hidden_states = encoder_hidden_states.last_hidden_state\n",
        "\n",
        "            # Predict the noise residual and compute loss\n",
        "            with torch.autocast('cuda', enabled=fp16):\n",
        "                noise_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
        "\n",
        "            loss = torch.nn.functional.mse_loss(noise_pred.float(), noise.float(), reduction=\"mean\")\n",
        "\n",
        "            # Backprop and all reduce\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Update EMA\n",
        "            if use_ema:\n",
        "                ema_unet.step(unet.parameters())\n",
        "\n",
        "            # perf\n",
        "            b_end = time.perf_counter()\n",
        "            seconds_per_step = b_end - b_start\n",
        "            steps_per_second = 1 / seconds_per_step\n",
        "            rank_images_per_second = batch_size * steps_per_second\n",
        "            world_images_per_second = rank_images_per_second * 1\n",
        "            samples_seen = global_step * batch_size * 1\n",
        "\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            global_step += 1\n",
        "            logs = {\n",
        "                \"train/loss\": loss.detach().item() / 1,\n",
        "                \"train/lr\": lr_scheduler.get_last_lr()[0],\n",
        "                \"train/epoch\": epoch,\n",
        "                \"train/step\": global_step,\n",
        "                \"train/samples_seen\": samples_seen,\n",
        "                \"perf/rank_samples_per_second\": rank_images_per_second,\n",
        "                \"perf/global_samples_per_second\": world_images_per_second,\n",
        "            }\n",
        "            progress_bar.set_postfix(logs)\n",
        "            run.log(logs, step=global_step)\n",
        "\n",
        "            if global_step % save_steps == 0:\n",
        "                save_checkpoint(global_step)\n",
        "\n",
        "            if enableinference:\n",
        "                if global_step % image_log_steps == 0:\n",
        "                    # get prompt from random batch\n",
        "                    prompt = tokenizer.decode(batch['input_ids'][random.randint(0, len(batch['input_ids'])-1)].tolist())\n",
        "\n",
        "                    # if args.image_log_scheduler == 'DDIMScheduler':\n",
        "                    #     print('using DDIMScheduler scheduler')\n",
        "                    #     scheduler = DDIMScheduler(\n",
        "                    #         beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\"\n",
        "                    #     )\n",
        "                    # else:\n",
        "                    print('using PNDMScheduler scheduler')\n",
        "                    scheduler=PNDMScheduler(\n",
        "                        beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True\n",
        "                    )\n",
        "\n",
        "                    pipeline = StableDiffusionPipeline(\n",
        "                        text_encoder=text_encoder,\n",
        "                        vae=vae,\n",
        "                        unet=unet,\n",
        "                        tokenizer=tokenizer,\n",
        "                        scheduler=scheduler,\n",
        "                        safety_checker=None, # disable safety checker to save memory\n",
        "                        feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\"),\n",
        "                    ).to(device)\n",
        "                    # inference\n",
        "                    if enablewandb:\n",
        "                        images = []\n",
        "                    else:\n",
        "                        saveInferencePath = output_path + \"/inference\"\n",
        "                        os.makedirs(saveInferencePath, exist_ok=True)\n",
        "                    with torch.no_grad():\n",
        "                        with torch.autocast('cuda', enabled=fp16):\n",
        "                            for _ in range(image_log_amount):\n",
        "                                if enablewandb:\n",
        "                                    images.append(\n",
        "                                        wandb.Image(pipeline(\n",
        "                                            prompt, num_inference_steps=image_log_inference_steps\n",
        "                                        ).images[0],\n",
        "                                        caption=prompt)\n",
        "                                    )\n",
        "                                else:\n",
        "                                    from datetime import datetime\n",
        "                                    images = pipeline(prompt, num_inference_steps=image_log_inference_steps).images[0]\n",
        "                                    filenameImg = str(time.time_ns()) + \".png\"\n",
        "                                    filenameTxt = str(time.time_ns()) + \".txt\"\n",
        "                                    images.save(saveInferencePath + \"/\" + filenameImg)\n",
        "                                    with open(saveInferencePath + \"/\" + filenameTxt, 'a') as f:\n",
        "                                        f.write('Used prompt: ' + prompt + '\\n')\n",
        "                                        f.write('Generated Image Filename: ' + filenameImg + '\\n')\n",
        "                                        f.write('Generated at: ' + str(global_step) + ' steps' + '\\n')\n",
        "                                        f.write('Generated at: ' + str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))+ '\\n')\n",
        "\n",
        "                    # log images under single caption\n",
        "                    if enablewandb:\n",
        "                        run.log({'images': images}, step=global_step)\n",
        "\n",
        "                    # cleanup so we don't run out of memory\n",
        "                    del pipeline\n",
        "                    gc.collect()\n",
        "except Exception as e:\n",
        "    print(f'Exception at step {global_step}, saving checkpoint...\\n{e}\\n{traceback.format_exc()}')\n",
        "    pass\n",
        "\n",
        "save_checkpoint(global_step)\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "iuMOn__d1npA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once the training has finished, you can download your model:\n"
      ],
      "metadata": {
        "id": "n5f2G4yp2ZkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 1: Google Drive"
      ],
      "metadata": {
        "id": "seFVBVHr2o6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run this cell to obtain what checkpoints are available\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(output_path)]\n",
        "print(\"Available Checkpoints:\")\n",
        "index = 0\n",
        "for i in onlyfiles:\n",
        "  index = index + 1\n",
        "  print(index, \"-\", i)\n",
        "print(\"The higher the number at the end, the more steps it has been trained for.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "bAcG7MoA24e-",
        "outputId": "8325d866-848f-49ff-98c2-bf77e2db5b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Checkpoints:\n",
            "The higher the number at the end, the more steps it has been trained for.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@markdown Select the step count below:\n",
        "step_count = 0 #@param {type:\"integer\"}\n",
        "#@markdown Select where to save:\n",
        "type_of_folder = \"Shared Drive\" #@param [\"My Drive\", \"Shared Drive\"]\n",
        "#@markdown If necesary, set a custom path to save at. Else leave it on \"none\"\n",
        "custom_path = \"gd-one\" #@param {type:\"string\"}\n",
        "\n",
        "model_to_save = output_path + \"/\" + run_name + \"_\" + str(step_count)\n",
        "print(\"Saving:\", model_to_save)\n",
        "\n",
        "if os.path.isdir(model_to_save):\n",
        "  print(\"Model does exist\")\n",
        "else:\n",
        "  raise Exception(\"Model does not exist. Check the parameters again please\")\n",
        "\n",
        "if type_of_folder == \"My Drive\":\n",
        "  if custom_path == \"none\":\n",
        "    path_to_save_at = \"/content/drive/MyDrive/\"\n",
        "  else:\n",
        "    path_to_save_at = \"/content/drive/MyDrive/\" + custom_path\n",
        "elif type_of_folder == \"Shared Drive\":\n",
        "  if custom_path == \"none\":\n",
        "    path_to_save_at = \"/content/drive/Shareddrives/\"\n",
        "  else:\n",
        "    path_to_save_at = \"/content/drive/Shareddrives/\" + custom_path\n",
        "\n",
        "print(\"Saving on:\", path_to_save_at)\n",
        "\n",
        "import shutil\n",
        "print(\"Saving... this might take a long time\")\n",
        "shutil.move(model_to_save, path_to_save_at)\n",
        "print(\"Model saved at\", path_to_save_at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "GMJ0TqOf2nff",
        "outputId": "70e2fea0-23fc-4462-cca6-0fd6663ef58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving: /content/output/myNewFinetune_0\n",
            "Model does exist\n",
            "Saving on: /content/drive/Shareddrives/gd-one\n",
            "Saving... this might take a long time\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/Shareddrives/gd-one/myNewFinetune_0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congratulations!\n",
        "You just trained your own finetune. You can now access it on the path provided path.\n",
        "\n",
        "Remember:\n",
        "\n",
        "### Diffuser format conversion to CKPT:\n",
        "The model is in diffusers format. Heres a convertor to CKPT: https://gist.github.com/chavinlo/93fd4bf910dfaa6781fbaec87b816493 \n",
        "\n",
        "Before running it, install `pip install torch OmegaConf`. Although you probably already have them.\n",
        "\n",
        "Download the model, its going to be a folder.\n",
        "\n",
        "Download the script.\n",
        "\n",
        "And execute `python3 --model_path PATH_TO_FOLDER_GOES_HERE --checkpoint_path PATH_TO_OUTPUT_CKPT_CHECKPOINT_GOES_HERE`\n",
        "\n",
        "## Support\n",
        "\n",
        "If you need help using this colab, or have suggestions, please let me know on the SD Training Labs discord server:\n",
        "\n",
        "https://discord.gg/8Sh2T6gjd2 - 2.2K members!!!\n",
        "\n",
        "## Distributed training & training platform\n",
        "You might want to train a bigger model (like, hundreds of thousands of images)\n",
        "\n",
        "I'm working on both distributed model training, and, a training web platform.\n",
        "\n",
        "This saturday (26th Nov.) we are going to conduct or first distributed training run! If you want to collaborate, join the server mentioned above. Help us by contributing your GPU compute power into a interconected hivemind!\n"
      ],
      "metadata": {
        "id": "pbDIEx1Z2jwe"
      }
    }
  ]
}